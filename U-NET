{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWlwqDHHq+vpXKwdnxDjlV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ridash2005/Pancreati-Tumor-Segmentation/blob/main/U-NET\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqws-ZpCjx4g"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install dependencies (skip if pre-installed)\n",
        "!pip install torch torchvision matplotlib\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 2: Define Dataset class to load images and masks\n",
        "class PancreaticTumorDataset(Dataset):\n",
        "    def __init__(self, image_paths, mask_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert('L')  # grayscale\n",
        "        mask = Image.open(self.mask_paths[idx]).convert('L')    # grayscale mask\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        # Normalize image and convert mask to binary tensor\n",
        "        image = transforms.ToTensor()(image)\n",
        "        mask = transforms.ToTensor()(mask)\n",
        "        mask = (mask > 0.5).float()  # Threshold mask to binary\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# Step 3: Define the U-Net model (classic architecture)\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        def conv_block(in_channels, out_channels):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.enc1 = conv_block(1, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = conv_block(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = conv_block(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.enc4 = conv_block(256, 512)\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.center = conv_block(512, 1024)\n",
        "\n",
        "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.dec4 = conv_block(1024, 512)\n",
        "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.dec3 = conv_block(512, 256)\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.dec2 = conv_block(256, 128)\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec1 = conv_block(128, 64)\n",
        "\n",
        "        self.final = nn.Conv2d(64, 1, kernel_size=1)  # output 1 channel mask\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(self.pool1(enc1))\n",
        "        enc3 = self.enc3(self.pool2(enc2))\n",
        "        enc4 = self.enc4(self.pool3(enc3))\n",
        "        center = self.center(self.pool4(enc4))\n",
        "        dec4 = self.up4(center)\n",
        "        dec4 = torch.cat([dec4, enc4], dim=1)\n",
        "        dec4 = self.dec4(dec4)\n",
        "        dec3 = self.up3(dec4)\n",
        "        dec3 = torch.cat([dec3, enc3], dim=1)\n",
        "        dec3 = self.dec3(dec3)\n",
        "        dec2 = self.up2(dec3)\n",
        "        dec2 = torch.cat([dec2, enc2], dim=1)\n",
        "        dec2 = self.dec2(dec2)\n",
        "        dec1 = self.up1(dec2)\n",
        "        dec1 = torch.cat([dec1, enc1], dim=1)\n",
        "        dec1 = self.dec1(dec1)\n",
        "\n",
        "        out = self.final(dec1)\n",
        "        return torch.sigmoid(out)  # sigmoid for binary mask\n",
        "\n",
        "# Step 4: Setup dataset paths & train/val split\n",
        "image_dir = '/content/drive/MyDrive/pancreatic_tumor_dataset/images'\n",
        "mask_dir = '/content/drive/MyDrive/pancreatic_tumor_dataset/masks'\n",
        "\n",
        "image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.png')])\n",
        "mask_files = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith('.png')])\n",
        "\n",
        "train_img, val_img, train_mask, val_mask = train_test_split(image_files, mask_files, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = PancreaticTumorDataset(train_img, train_mask, transform=None)\n",
        "val_dataset = PancreaticTumorDataset(val_img, val_mask, transform=None)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "\n",
        "# Step 5: Initialize model, loss, optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNet().to(device)\n",
        "criterion = nn.BCELoss()  # can also use Dice loss or combo\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Step 6: Training loop with validation\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, masks in train_loader:\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch} Training Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "def validate():\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            val_loss += loss.item()\n",
        "    print(f\"Validation Loss: {val_loss/len(val_loader):.4f}\")\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train(epoch)\n",
        "    validate()\n",
        "\n",
        "# Step 7: Inference and visualization on validation samples\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    images, masks = next(iter(val_loader))\n",
        "    images = images.to(device)\n",
        "    outputs = model(images)\n",
        "    outputs = outputs.cpu().numpy()\n",
        "\n",
        "fig, axs = plt.subplots(3, 4, figsize=(12, 9))\n",
        "for i in range(4):\n",
        "    axs[0, i].imshow(images[i].cpu().squeeze(), cmap='gray')\n",
        "    axs[0, i].set_title('Input Image')\n",
        "    axs[0, i].axis('off')\n",
        "\n",
        "    axs[1, i].imshow(masks[i].squeeze(), cmap='gray')\n",
        "    axs[1, i].set_title('Ground Truth')\n",
        "    axs[1, i].axis('off')\n",
        "\n",
        "    axs[2, i].imshow(outputs[i].squeeze(), cmap='gray')\n",
        "    axs[2, i].set_title('Predicted Mask')\n",
        "    axs[2, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ]
}